{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/workspaces/ragbot/notebooks\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load rails application\n",
    "require_relative \"../config/environment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":index_vectors"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def index_vectors(content_fragments, offset: 0, batch_size: 20)\n",
    "  client = OpenAI::Client.new(access_token: ENV[\"OPENAI_API_KEY\"])\n",
    "\n",
    "  content_fragments_indexes = []\n",
    "\n",
    "  content_fragments[offset..].each_slice(batch_size) do |batch|\n",
    "    response = client.embeddings(parameters: {\n",
    "      model: \"text-embedding-3-small\",\n",
    "      input: batch.map(&:body)\n",
    "    })\n",
    "\n",
    "    ids = batch.map(&:id)\n",
    "    content_fragments_indexes += ids\n",
    "      .zip(response[\"data\"].map { |vector| vector[\"embedding\"] })\n",
    "      .map { |entry| { id: entry[0], embedding: entry[1] } }\n",
    "  end\n",
    "\n",
    "  IndexContentFragments.call(content_fragments_indexes)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ruby 3.3.0",
   "language": "ruby",
   "name": "ruby"
  },
  "language_info": {
   "file_extension": ".rb",
   "mimetype": "application/x-ruby",
   "name": "ruby",
   "version": "3.3.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
